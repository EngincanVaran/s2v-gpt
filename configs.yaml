global_configs:
  exp_num: 1

training_configs:
  # Basic training parameters
  batch_size: 4096 # Number of samples processed before the model is updated
  epochs: 5
  eval_interval: 100
  learning_rate: 0.0003
  data_split: 1
  step_size: 1
  gamma: 0.9

model_configs:
  # Model configuration
  vocab_size: 4096  # The size of the vocabulary
  n_layer: 2  # The number of transformer layers
  n_head: 4  # The number of attention heads in each transformer layer
  n_embd: 64  # The dimensionality of embeddings and hidden layers
  block_size: 32  # The maximum length of input sequences
  # Regularization and optimization
  dropout: 0  # Dropout rate to prevent overfitting
  bias: true  # Whether to include bias terms in linear layers
